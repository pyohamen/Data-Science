{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 서포트 벡터 머신 (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  박태영 교수\n",
    "### 연세대학교 응용통계학과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline\n",
    "\n",
    "### 4. SVM 최적화 및 성능평가\n",
    "    4.1 파이프라인\n",
    "    4.2 k-겹 교차검증\n",
    "    4.3 그리드 서치를 이용한 SVM 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 파이프라인\n",
    "\n",
    "- 데이터 전처리 및 모형 학습에 대한 일련의 과정을 하나의 단일 과정으로 만듬\n",
    "- 교차검증을 수행하고 모형을 최적화하기 위해서 반복되는 작업의 실행을 단순화\n",
    "- 필요한 모듈을 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.patches as mpatches \n",
    "from IPython.display import Image\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 반도체 생산 과정에서 590개의 센서로부터 얻은 데이터\n",
    "- 590개의 숫자형 특성변수, **정상/비정상**에 대한 범주변수(-1:정상,1:비정상)로 구성\n",
    "- 목적: 새로운 반도체 센서 데이터가 주어졌을 때, 비정상을 예측 분류\n",
    "- 출처: http://archive.ics.uci.edu/ml/datasets/secom  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Secom.csv')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 결측 비율이 10%이상인 특성 변수 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = data.isnull().sum() / len(data)\n",
    "data_com = data.loc[:,[x < 0.1 for x in missing]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 결측값의 평균값 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data2 = data_com\n",
    "data1.fillna(method = 'ffill', inplace = True) # 이전 시점 값으로 대체\n",
    "data2.fillna(method = 'bfill', inplace = True) # 이후 시점 값으로 대체\n",
    "data_com = (data1+data2)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 특성 변수 및 범주 변수의 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_com.iloc[:,:-1] # 특성 변수\n",
    "y = (data_com.iloc[:,-1]+1)/2 # 범주 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 과대표집(oversampling)을 위해 SMOTE (Synthetic Minority Oversampling Technique) 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='Sampling.png', width=500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "SMOTE = SMOTE()\n",
    "X2, y2 = SMOTE.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imblearn # SMOTE를 사용하기 위해 imblearn 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install delayed # imblearn 설치를 위해 delayed 설치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `imblearn`과 `delayed`를 설치한 이후에도 설치가 안되었다고 에러가 발생하는 경우 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipython # 주피터 노트북의 파이썬 커널 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install ipykernel # 가상 환경에서 주피터 노트북 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m ipykernel install --user # 주피터 노트북에 파이썬 커널 등록 후 주피터 노트북 완전히 종료 후 다시 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 훈련용 데이터와 테스트용 데이터를 7:3의 비율로 분리하고 y 비율이 동일하게 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X2, y2, test_size=0.3, random_state=1, stratify=y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Pipeline`을 통해 전처리 및 모형 학습의 과정을 하나의 과정으로 묶어줌\n",
    "- 예를 들면, **'표준화 + PCA + SVM'**을 한꺼번에 묶음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), # 표준화\n",
    "                     PCA(n_components=10), # PCA\n",
    "                     SVC(kernel='rbf', gamma='auto', C=1)) # SVM\n",
    "\n",
    "pipe.fit(X_train, y_train) # 표준화 + PCA + SVM\n",
    "y_pred = pipe.predict(X_test) # 예측값\n",
    "print('Accuracy: %.3f' % pipe.score(X_test, y_test)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 k-겹 교차검증 (k-fold cross validation)\n",
    "\n",
    "- 머신러닝 알고리즘의 모수값을 디폴트로 정하지 않고 최적화하고자 할 때, 동일한 테스트용 데이터를 이용하면 과적합의 위험이 존재\n",
    "- 훈련용 데이터를 \"훈련용 데이터 + 검증용 데이터\"로 나눠 모수값을 최적화하는 데 사용\n",
    "- 특정 검증용 데이터에 과적합하는 것을 방지하기 위해 여러 겹으로 나누어 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "CVS = cross_val_score(estimator=pipe, X=X_train, y=y_train, cv=10) # 10-겹 교차검증\n",
    "print(CVS)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(CVS), np.std(CVS)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 정확도 외에 정밀도, 재현율, F1점수를 기준으로 교차검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "CVS2 = cross_val_score(estimator=pipe, X=X_train, y=y_train, cv=10, scoring=make_scorer(precision_score)) # 정밀도\n",
    "CVS3 = cross_val_score(estimator=pipe, X=X_train, y=y_train, cv=10, scoring=make_scorer(recall_score))    # 재현율 \n",
    "CVS4 = cross_val_score(estimator=pipe, X=X_train, y=y_train, cv=10, scoring=make_scorer(f1_score))        # F1점수\n",
    "\n",
    "print('CV precision: %.3f +/- %.3f' % (np.mean(CVS2), np.std(CVS2)))\n",
    "print('CV recall   : %.3f +/- %.3f' % (np.mean(CVS3), np.std(CVS3)))\n",
    "print('CV F1 score : %.3f +/- %.3f' % (np.mean(CVS4), np.std(CVS4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 훈련용 데이터의 정확도와 교차검증의 정확도 비교\n",
    "- SVM의 모수 C의 값을 변화하면서 비교\n",
    "- 모형의 모수값을 나타내는 방법: 모형과 모수 사이에 `__`를 붙여줌 (예: `svc__C`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     SVC(kernel='rbf', gamma='auto')) \n",
    "\n",
    "param_range = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0] # 하나의 모수(C)에 대한 여러 후보값\n",
    "train_scores, cv_scores = validation_curve(estimator=pipe, \n",
    "                                           X=X_train, y=y_train, \n",
    "                                           param_name='svc__C', \n",
    "                                           param_range=param_range, \n",
    "                                           cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **과소적합**: 훈련용 데이터의 정확도와 교차검증의 정확도가 모두 낮은 경우\n",
    "- **과대적합**: 훈련용 데이터의 정확도는 높으나 교차검증의 정확도는 낮은 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "cv_mean = np.mean(cv_scores, axis=1)\n",
    "cv_std = np.std(cv_scores, axis=1)\n",
    "\n",
    "print(\"Training score: \", train_mean)\n",
    "print(\"CV score      : \", cv_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 검증곡선(validation curve)의 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(param_range, train_mean, color='b', marker='o', markersize=5, \n",
    "         label='Training accuracy')\n",
    "\n",
    "plt.fill_between(param_range, train_mean + train_std, train_mean - train_std, \n",
    "                 alpha=0.15, color='b')\n",
    "\n",
    "plt.plot(param_range, cv_mean, color='g', linestyle='--', marker='s', markersize=5, \n",
    "         label='CV accuracy')\n",
    "\n",
    "plt.fill_between(param_range, cv_mean + cv_std, cv_mean - cv_std, \n",
    "                 alpha=0.15, color='g')\n",
    "\n",
    "plt.grid()\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('Parameter C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.8, 1.0])\n",
    "plt.savefig('VC.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 그리드 서치를 이용한 SVM 최적화\n",
    "\n",
    "- 여러 모형과 모수의 여러 후보값을 고려하여 머신러닝 알고리즘을 최적화\n",
    "- 그리드 서치(grid search)를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), SVC()) \n",
    "\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "\n",
    "param_grid = [{'svc__C': param_range, 'svc__kernel': ['linear']},\n",
    "              {'svc__C': param_range, 'svc__kernel': ['rbf'], 'svc__gamma': param_range}]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe, \n",
    "                  param_grid=param_grid, \n",
    "                  scoring='accuracy', \n",
    "                  cv=10, \n",
    "                  n_jobs=-1) # n_jobs=-1 uses all processors\n",
    "gs = gs.fit(X_train, y_train)\n",
    "\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = gs.best_estimator_\n",
    "svm.fit(X_train, y_train)\n",
    "print('Accuracy: %.3f' % svm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  그리드 서치에서 정확도가 아닌 다른 지표(정밀도, 재현율, F1점수)로 최적의 알고리즘을 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scoring = make_scorer(precision_score) # 정밀도\n",
    "scoring = make_scorer(recall_score)    # 재현율 \n",
    "#scoring = make_scorer(f1_score)        # F1점수\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), SVC()) \n",
    "\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "\n",
    "param_grid = [{'svc__C': param_range, 'svc__kernel': ['linear']},\n",
    "              {'svc__C': param_range, 'svc__kernel': ['rbf'], 'svc__gamma': param_range}]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe, \n",
    "                  param_grid=param_grid, \n",
    "                  scoring=scoring, # 다른 지표를 사용 \n",
    "                  cv=10, \n",
    "                  n_jobs=-1) # n_jobs=-1 uses all processors\n",
    "gs = gs.fit(X_train, y_train)\n",
    "\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gs.best_estimator_.predict(X_test)\n",
    "\n",
    "print('Accuracy : %.3f' % accuracy_score(y_true=y_test, y_pred=y_pred))\n",
    "print('Precision: %.3f' % precision_score(y_true=y_test, y_pred=y_pred))\n",
    "print('Recall   : %.3f' % recall_score(y_true=y_test, y_pred=y_pred))\n",
    "print('F1 score : %.3f' % f1_score(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
