{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np                                             #넘파이:벡터행렬연산, 수학함수계산\n",
    "from scipy import stats                                        #싸이파이:수치해석, stats:확률분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  default student      balance        income\n",
       "0      No      No   729.526495  44361.625074\n",
       "1      No     Yes   817.180407  12106.134700\n",
       "2      No      No  1073.549164  31767.138947\n",
       "3      No      No   529.250605  35704.493935\n",
       "4      No      No   785.655883  38463.495879"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft = pd.read_csv('../Data/Default.csv')\n",
    "dft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmp/opt/anaconda3/envs/yonsei/lib/python3.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/hmp/opt/anaconda3/envs/yonsei/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "      <th>studentYes</th>\n",
       "      <th>defaultYes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>0.044362</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>0.012106</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>0.031767</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>0.035704</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>0.038463</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  default student      balance    income  studentYes  defaultYes\n",
       "0      No      No   729.526495  0.044362           0           0\n",
       "1      No     Yes   817.180407  0.012106           1           0\n",
       "2      No      No  1073.549164  0.031767           0           0\n",
       "3      No      No   529.250605  0.035704           0           0\n",
       "4      No      No   785.655883  0.038463           0           0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 범주형을 0,1 로 변환 후, 새로운 피쳐로 저장\n",
    "# income 피처는 덮어쓰기로 저장\n",
    "dft['studentYes'] = (dft['student']=='Yes').astype(np.int)      #또는 np.multiply(dft['student']=='Yes',1)\n",
    "dft['defaultYes'] = (dft['default']=='Yes').astype(np.int)      #또는 np.multiply(dft['default']=='Yes',1)\n",
    "dft['income'] = dft['income']/1000                              #income in tho. dollars\n",
    "dft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glm 함수는 일반화선형모형, 회귀분석, 로지스틱 회귀분석을 포함\n",
    "# 회귀분석은 정규분포 혹은 가우시안 분포\n",
    "# 로지스틱은 베르누이분포 바이노미알 분포\n",
    "# glm 은 포아성분포, 감마분포\n",
    "\n",
    "import statsmodels.api as sm                                    #통계모형  \n",
    "import statsmodels.formula.api as smf # 로지스틱 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>defaultYes</td>    <th>  No. Observations:  </th>  <td> 10000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>  9998</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>     1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -1454.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 17 Mar 2021</td> <th>  Deviance:          </th> <td>  2908.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>16:22:50</td>     <th>  Pearson chi2:      </th> <td>1.00e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>6</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>   -3.5041</td> <td>    0.071</td> <td>  -49.554</td> <td> 0.000</td> <td>   -3.643</td> <td>   -3.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>studentYes</th> <td>    0.4049</td> <td>    0.115</td> <td>    3.520</td> <td> 0.000</td> <td>    0.179</td> <td>    0.630</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:             defaultYes   No. Observations:                10000\n",
       "Model:                            GLM   Df Residuals:                     9998\n",
       "Model Family:                Binomial   Df Model:                            1\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -1454.3\n",
       "Date:                Wed, 17 Mar 2021   Deviance:                       2908.7\n",
       "Time:                        16:22:50   Pearson chi2:                 1.00e+04\n",
       "No. Iterations:                     6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -3.5041      0.071    -49.554      0.000      -3.643      -3.366\n",
       "studentYes     0.4049      0.115      3.520      0.000       0.179       0.630\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# formula: 왼쩍이 반응변수, 오른쪽이 설명변수\n",
    "# 로그오즈를 선형변수\n",
    "# 절편은 따로 명시 안 해도 포함됨, 포함하고 싶으면 -1을 ''안에 포함\n",
    "# 만약 ~ 뒤에 1 쓰면 설명변수 없는 상수함수가 됨\n",
    "# 로지스틱일 땐 family 로 binomial 을 명시해줘야 함, 안 쓰면 선형회귀분석됨\n",
    "# fit(): 모형적합\n",
    "\n",
    "fit1 = smf.glm(formula = 'defaultYes~studentYes', data=dft, family=sm.families.Binomial()).fit()\n",
    "\n",
    "# 모형적합의 결과\n",
    "fit1.summary()\n",
    "\n",
    "# Observations: 관측개수\n",
    "# Df: 자유도\n",
    "\n",
    "#n 개의 관측치가 있으면 전체 자유도는 n\n",
    "#모형을 표현하는 모수의 갯수가 모형의 자유도\n",
    "#n 에서 모형의 자유도를 뺀게 잔차의 자유도\n",
    "#때로는 절편을 제외한 것을 모형의 자유도로 보기도 함\n",
    "\n",
    "# Log-Likelihood: 가능도에 로그를 취한 것, 적합된 모형의 로그 가능도\n",
    "\n",
    "# 아래 추론값이 나와 이로 로그오즈를 구하고\n",
    "# 로그오즈로 확률함수를 구한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>defaultYes</td>    <th>  No. Observations:  </th>  <td> 10000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>  9998</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>     1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -798.23</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 17 Mar 2021</td> <th>  Deviance:          </th> <td>  1596.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>16:34:52</td>     <th>  Pearson chi2:      </th> <td>7.15e+03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>9</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  -10.6513</td> <td>    0.361</td> <td>  -29.491</td> <td> 0.000</td> <td>  -11.359</td> <td>   -9.943</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>balance</th>   <td>    0.0055</td> <td>    0.000</td> <td>   24.952</td> <td> 0.000</td> <td>    0.005</td> <td>    0.006</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:             defaultYes   No. Observations:                10000\n",
       "Model:                            GLM   Df Residuals:                     9998\n",
       "Model Family:                Binomial   Df Model:                            1\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -798.23\n",
       "Date:                Wed, 17 Mar 2021   Deviance:                       1596.5\n",
       "Time:                        16:34:52   Pearson chi2:                 7.15e+03\n",
       "No. Iterations:                     9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    -10.6513      0.361    -29.491      0.000     -11.359      -9.943\n",
       "balance        0.0055      0.000     24.952      0.000       0.005       0.006\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 설명변수가 달라짐\n",
    "\n",
    "fit2 = smf.glm(formula = 'defaultYes~balance', data=dft, family=sm.families.Binomial()).fit()\n",
    "fit2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                2.5%     97.5%      coef\n",
      "Intercept  -3.642723 -3.365533 -3.504128\n",
      "studentYes  0.179454  0.630320  0.404887\n"
     ]
    }
   ],
   "source": [
    "dir(fit1)\n",
    "conf = fit1.conf_int()\n",
    "conf['coef'] = fit1.params\n",
    "conf.columns = ['2.5%', '97.5%', 'coef']\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                2.5%     97.5%  Odds Ratio\n",
      "Intercept   0.026181  0.034544    0.030073\n",
      "studentYes  1.196564  1.878211    1.499133\n"
     ]
    }
   ],
   "source": [
    "conf_OR=np.exp(conf)\n",
    "conf_OR.columns = ['2.5%', '97.5%', 'Odds Ratio']\n",
    "print(conf_OR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>defaultYes</td>    <th>  No. Observations:  </th>  <td> 10000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>  9996</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>     3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -785.77</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 17 Mar 2021</td> <th>  Deviance:          </th> <td>  1571.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>16:11:35</td>     <th>  Pearson chi2:      </th> <td>7.00e+03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>9</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>  -10.8690</td> <td>    0.492</td> <td>  -22.079</td> <td> 0.000</td> <td>  -11.834</td> <td>   -9.904</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>balance</th>    <td>    0.0057</td> <td>    0.000</td> <td>   24.737</td> <td> 0.000</td> <td>    0.005</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income</th>     <td>    3.0335</td> <td>    8.203</td> <td>    0.370</td> <td> 0.712</td> <td>  -13.044</td> <td>   19.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>studentYes</th> <td>   -0.6468</td> <td>    0.236</td> <td>   -2.738</td> <td> 0.006</td> <td>   -1.110</td> <td>   -0.184</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:             defaultYes   No. Observations:                10000\n",
       "Model:                            GLM   Df Residuals:                     9996\n",
       "Model Family:                Binomial   Df Model:                            3\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -785.77\n",
       "Date:                Wed, 17 Mar 2021   Deviance:                       1571.5\n",
       "Time:                        16:11:35   Pearson chi2:                 7.00e+03\n",
       "No. Iterations:                     9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    -10.8690      0.492    -22.079      0.000     -11.834      -9.904\n",
       "balance        0.0057      0.000     24.737      0.000       0.005       0.006\n",
       "income         3.0335      8.203      0.370      0.712     -13.044      19.111\n",
       "studentYes    -0.6468      0.236     -2.738      0.006      -1.110      -0.184\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit3 = smf.glm(formula = 'defaultYes~balance+income+studentYes', data=dft, family=sm.families.Binomial()).fit()\n",
    "fit3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 2.5%      97.5%       coef        se\n",
      "Intercept  -11.833882  -9.904209 -10.869045  0.492273\n",
      "balance      0.005282   0.006191   0.005737  0.000232\n",
      "income     -13.043675  19.110575   3.033450  8.202766\n",
      "studentYes  -1.109831  -0.183721  -0.646776  0.236257\n"
     ]
    }
   ],
   "source": [
    "dir(fit3)\n",
    "conf = fit3.conf_int()\n",
    "conf['coef'] = fit3.params\n",
    "conf['se'] = fit3.bse\n",
    "conf.columns = ['2.5%', '97.5%', 'coef', 'se']\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 0.5%      99.5%\n",
      "Intercept  -12.137056  -9.601035\n",
      "balance      0.005139   0.006334\n",
      "income     -18.095474  24.162374\n",
      "studentYes  -1.255333  -0.038218\n"
     ]
    }
   ],
   "source": [
    "conf99 = pd.DataFrame()\n",
    "conf99['0.5%'] = fit3.params + stats.norm.ppf(0.005)*fit3.bse\n",
    "conf99['99.5%'] = fit3.params + stats.norm.ppf(0.995)*fit3.bse\n",
    "print(conf99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dft[\"defaultYes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9667\n",
       "1     333\n",
       "Name: defaultYes, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft[\"defaultYes\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9625   42]\n",
      " [ 233  100]]\n"
     ]
    }
   ],
   "source": [
    "pred_p = fit2.predict()   \n",
    "pred_c1 = [ 1 if x > 0.5 else 0 for x in pred_p]\n",
    "print(confusion_matrix(dft[\"defaultYes\"], pred_c1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7864 1803]\n",
      " [  22  311]]\n"
     ]
    }
   ],
   "source": [
    "pred_c2 = [ 1 if x > 0.02 else 0 for x in pred_p]\n",
    "print(confusion_matrix(dft[\"defaultYes\"], pred_c2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bankrupt data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm                                                                                 #통계모형  \n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.56</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>1.51</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x1    x2    x3    x4  y\n",
       "0 -0.45 -0.41  1.09  0.45  0\n",
       "1 -0.56 -0.31  1.51  0.16  0\n",
       "2  0.06  0.02  1.01  0.40  0\n",
       "3 -0.07 -0.09  1.45  0.26  0\n",
       "4 -0.10 -0.09  1.56  0.67  0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank = pd.read_table('../data/bankrupt.txt', sep=\"\\s+\")  #하나 이상의 스페이스 sep=\"\\s+\"\n",
    "bank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>    46</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>    41</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>     4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -13.722</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 29 Mar 2021</td> <th>  Deviance:          </th> <td>  27.443</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>12:14:34</td>     <th>  Pearson chi2:      </th>  <td>  54.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>7</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -5.3195</td> <td>    2.366</td> <td>   -2.248</td> <td> 0.025</td> <td>   -9.958</td> <td>   -0.681</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>        <td>    7.1378</td> <td>    6.002</td> <td>    1.189</td> <td> 0.234</td> <td>   -4.625</td> <td>   18.901</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>        <td>   -3.7033</td> <td>   13.670</td> <td>   -0.271</td> <td> 0.786</td> <td>  -30.497</td> <td>   23.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>        <td>    3.4148</td> <td>    1.204</td> <td>    2.837</td> <td> 0.005</td> <td>    1.056</td> <td>    5.774</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>        <td>   -2.9684</td> <td>    3.065</td> <td>   -0.968</td> <td> 0.333</td> <td>   -8.976</td> <td>    3.040</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                   46\n",
       "Model:                            GLM   Df Residuals:                       41\n",
       "Model Family:                Binomial   Df Model:                            4\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -13.722\n",
       "Date:                Mon, 29 Mar 2021   Deviance:                       27.443\n",
       "Time:                        12:14:34   Pearson chi2:                     54.1\n",
       "No. Iterations:                     7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -5.3195      2.366     -2.248      0.025      -9.958      -0.681\n",
       "x1             7.1378      6.002      1.189      0.234      -4.625      18.901\n",
       "x2            -3.7033     13.670     -0.271      0.786     -30.497      23.090\n",
       "x3             3.4148      1.204      2.837      0.005       1.056       5.774\n",
       "x4            -2.9684      3.065     -0.968      0.333      -8.976       3.040\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm2=smf.glm(formula = 'y ~ x1 + x2 + x3 + x4', \n",
    "           data=bank, family=sm.families.Binomial()).fit()\n",
    "fm2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "37.44323448446937\n",
      "37.44323448446937\n"
     ]
    }
   ],
   "source": [
    "print(fm2.df_model)\n",
    "print(-2*fm2.llf + 2*(fm2.df_model+1)) # 여기서는 df_model = (모수의 갯수 - 1(보통 상수항)) 로 정의\n",
    "print(fm2.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.58644146691485\n",
      "46.58644146691485\n"
     ]
    }
   ],
   "source": [
    "print(-2*fm2.llf + np.log(fm2.nobs)*(fm2.df_model+1)) # 여기서는 df_model = (모수의 갯수-1(보통 상수항)) 로 정의\n",
    "print(fm2.bic_llf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-13.721617242234684\n",
      "-13.721617242234684\n"
     ]
    }
   ],
   "source": [
    "p=fm2.predict()\n",
    "y=bank[\"y\"]\n",
    "print(sum(y*np.log(p)+(1-y)*np.log(1-p)))                # loglikelihood\n",
    "print(fm2.llf)                                           # loglikelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection: Forward (by hand)\n",
    "> 전진탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.42127484920293"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.glm('y~1', data=bank,\n",
    "        family=sm.families.Binomial()).fit().aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.6502469534637"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.glm('y~x1', data=bank,\n",
    "        family=sm.families.Binomial()).fit().aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.85715656400864"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.glm('y~x2', data=bank,\n",
    "        family=sm.families.Binomial()).fit().aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.34399025597335"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.glm('y~x3', data=bank,\n",
    "        family=sm.families.Binomial()).fit().aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67.38101453637978"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.glm('y~x4', data=bank,\n",
    "        family=sm.families.Binomial()).fit().aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.34399025597335"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.glm('y~x3', data=bank,\n",
    "        family=sm.families.Binomial()).fit().aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.63561349297248"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.glm('y~x3+x1', data=bank,\n",
    "        family=sm.families.Binomial()).fit().aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.82850016937259"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.glm('y~x3+x2', data=bank,\n",
    "        family=sm.families.Binomial()).fit().aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.764372136654615"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.glm('y~x3+x4', data=bank,\n",
    "        family=sm.families.Binomial()).fit().aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.514336009819885"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.glm('y~x3+x1+x2', data=bank,\n",
    "        family=sm.families.Binomial()).fit().aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.516314435067855"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.glm('y~x3+x1+x4', data=bank,\n",
    "        family=sm.families.Binomial()).fit().aic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [F] forward_logistic_aic 함수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmp/opt/anaconda3/envs/yonsei/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.56</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>1.51</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x1    x2    x3    x4\n",
       "0 -0.45 -0.41  1.09  0.45\n",
       "1 -0.56 -0.31  1.51  0.16\n",
       "2  0.06  0.02  1.01  0.40\n",
       "3 -0.07 -0.09  1.45  0.26\n",
       "4 -0.10 -0.09  1.56  0.67"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=bank.iloc[:,0:4]                       #dataframe\n",
    "y=bank.iloc[:,4].astype(np.int)\n",
    "X.head()\n",
    "#y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%%% forward\n",
    "def forward_logistic_aic(data, X, y, verbose=True):\n",
    "    add_list=list(X.columns)\n",
    "    included = []\n",
    "    while True:\n",
    "        changed=False\n",
    "        \n",
    "        if included:\n",
    "            formula = 'y~{}'.format('+'.join(included))\n",
    "        else:\n",
    "            formula = 'y~1'\n",
    "        model = smf.glm(formula, data, family=sm.families.Binomial()).fit()\n",
    "        \n",
    "        aic = {}\n",
    "        aic['none'] = model.aic\n",
    "        \n",
    "        print('Step : AIC =',aic['none'].round(3))\n",
    "        print(formula)\n",
    "    \n",
    "        for add in add_list:\n",
    "            remain = included + [add]\n",
    "            formula = 'y~{}'.format('+'.join(remain))\n",
    "            model = smf.glm(formula, data, family=sm.families.Binomial()).fit()\n",
    "            aic[add] = model.aic\n",
    "        aic_sort = sorted(aic.items(), key=lambda x:x[1])\n",
    "        \n",
    "        print('\\t AIC')\n",
    "        for item, key in aic_sort:\n",
    "            if(item=='none'):\n",
    "                print('<',item,'>','\\t ',key.round(3),sep='')\n",
    "            else:\n",
    "                print('+',item,'\\t',key.round(3))\n",
    "        \n",
    "        #display(aic_sort)\n",
    "        aic_min = aic_sort[0][1]\n",
    "        if aic_min < aic['none']:\n",
    "            changed=True\n",
    "            best_feature = aic_sort[0][0]\n",
    "            included.append(best_feature)\n",
    "            add_list.remove(best_feature)\n",
    "            if verbose:\n",
    "                print('>> Add {} with AIC {} \\n'.format(best_feature, aic_min.round(3)))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step : AIC = 65.421\n",
      "y~1\n",
      "\t AIC\n",
      "+ x3 \t 39.344\n",
      "+ x1 \t 47.65\n",
      "+ x2 \t 47.857\n",
      "<none>\t 65.421\n",
      "+ x4 \t 67.381\n",
      ">> Add x3 with AIC 39.344 \n",
      "\n",
      "Step : AIC = 39.344\n",
      "y~x3\n",
      "\t AIC\n",
      "+ x1 \t 34.636\n",
      "+ x2 \t 36.829\n",
      "+ x4 \t 38.764\n",
      "<none>\t 39.344\n",
      ">> Add x1 with AIC 34.636 \n",
      "\n",
      "Step : AIC = 34.636\n",
      "y~x3+x1\n",
      "\t AIC\n",
      "<none>\t 34.636\n",
      "+ x4 \t 35.516\n",
      "+ x2 \t 36.514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['x3', 'x1']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_logistic_aic(bank, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [B] backward_logistic_aic 함수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%%% backward\n",
    "def backward_logistic_aic(data, X, y, verbose=True):\n",
    "    included=list(X.columns)\n",
    "    while True:\n",
    "        changed=False\n",
    "        formula = 'y~{}'.format('+'.join(included))\n",
    "        model = smf.glm(formula, data, family=sm.families.Binomial()).fit()\n",
    "        aic = {}\n",
    "        aic['none'] = model.aic\n",
    "        \n",
    "        print('Step : AIC =',aic['none'].round(3))\n",
    "        print(formula)\n",
    "    \n",
    "        for drop in included:\n",
    "            remain = list(set(included)-set([drop]))\n",
    "            formula = 'y~{}'.format('+'.join(remain))\n",
    "            model = smf.glm(formula, data, family=sm.families.Binomial()).fit()\n",
    "            aic[drop] = model.aic\n",
    "        aic_sort = sorted(aic.items(), key=lambda x:x[1])\n",
    "        \n",
    "        \n",
    "        print('\\t AIC')\n",
    "        for item, key in aic_sort:\n",
    "            if(item=='none'):\n",
    "                print('<',item,'>','\\t ',key.round(3),sep='')\n",
    "            else:\n",
    "                print('-',item,'\\t',key.round(3))\n",
    "        \n",
    "        #display(aic_sort)\n",
    "        aic_min = aic_sort[0][1]\n",
    "        if aic_min < aic['none']:\n",
    "            changed=True\n",
    "            worst_feature = aic_sort[0][0]\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('>> Drop {} with AIC {} \\n'.format(worst_feature, aic_min.round(3)))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step : AIC = 37.443\n",
      "y~x1+x2+x3+x4\n",
      "\t AIC\n",
      "- x2 \t 35.516\n",
      "- x4 \t 36.514\n",
      "- x1 \t 37.133\n",
      "<none>\t 37.443\n",
      "- x3 \t 50.56\n",
      ">> Drop x2 with AIC 35.516 \n",
      "\n",
      "Step : AIC = 35.516\n",
      "y~x1+x3+x4\n",
      "\t AIC\n",
      "- x4 \t 34.636\n",
      "<none>\t 35.516\n",
      "- x1 \t 38.764\n",
      "- x3 \t 49.624\n",
      ">> Drop x4 with AIC 34.636 \n",
      "\n",
      "Step : AIC = 34.636\n",
      "y~x1+x3\n",
      "\t AIC\n",
      "<none>\t 34.636\n",
      "- x1 \t 39.344\n",
      "- x3 \t 47.65\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['x1', 'x3']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backward_logistic_aic(bank, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [S] stepwise_logistic_aic 함수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepwise_logistic_aic_scope(data, X, y, \n",
    "                                start=[], upper=[], lower=[], \n",
    "                                verbose=True):\n",
    "    \n",
    "    add_list = X.columns\n",
    "    \n",
    "    \n",
    "    if not start:\n",
    "        start = list(X.columns)    \n",
    "    if not upper:\n",
    "        upper = list(X.columns)\n",
    "   \n",
    "    included = start[:]\n",
    "    add_list = [x for x in add_list if x not in included]\n",
    "    \n",
    "    while True:\n",
    "        changed=False\n",
    "        \n",
    "        if included:\n",
    "            formula = 'y~{}'.format('+'.join(included))\n",
    "        else:\n",
    "            formula = 'y~1'\n",
    "            \n",
    "        model = smf.glm(formula, data,family=sm.families.Binomial()).fit()\n",
    "        \n",
    "        aic = {}\n",
    "        aic['none'] = model.aic\n",
    "        \n",
    "        print('Step : AIC =',aic['none'].round(3))\n",
    "        print(formula)\n",
    "        \n",
    "    \n",
    "        for drop in included:\n",
    "            remain = [x for x in included if x not in [drop]]\n",
    "            if remain:\n",
    "                formula = 'y~{}'.format('+'.join(remain))\n",
    "            else:\n",
    "                formula = 'y~1'\n",
    "            model = smf.glm(formula, data, family=sm.families.Binomial()).fit()\n",
    "            aic[drop] = model.aic\n",
    "                \n",
    "        for add in add_list:\n",
    "            remain = included + [add]\n",
    "            formula = 'y~{}'.format('+'.join(remain))\n",
    "            model = smf.glm(formula, data, family=sm.families.Binomial()).fit()\n",
    "            aic[add] = model.aic\n",
    "        \n",
    "        aic_sort = sorted(aic.items(), key=lambda x:x[1])\n",
    "        \n",
    "        print('\\t AIC')\n",
    "        for item, key in aic_sort:\n",
    "            if(item=='none'):\n",
    "                print('<',item,'>','\\t ',key.round(3),sep='')\n",
    "            else:\n",
    "                if pd.Series(item).isin(included).bool():\n",
    "                    print('-',item,'\\t',key.round(3))\n",
    "                else:\n",
    "                    print('+',item,'\\t',key.round(3))\n",
    "                    \n",
    "        \n",
    "        #display(aic_sort)\n",
    "        aic_min = aic_sort[0][1]\n",
    "        if aic_min < aic['none']:\n",
    "            changed=True\n",
    "            ch_feature = aic_sort[0][0]\n",
    "            if pd.Series(ch_feature).isin(included).bool():\n",
    "                included.remove(ch_feature)\n",
    "                add_list.append(ch_feature) \n",
    "                if verbose:\n",
    "                    print('>> Drop {} with AIC {} \\n'.format(ch_feature, aic_min.round(3)))\n",
    "            else:\n",
    "                included.append(ch_feature)\n",
    "                add_list.remove(ch_feature)\n",
    "                if verbose:\n",
    "                    print('>> Add {} with AIC {} \\n'.format(ch_feature, aic_min.round(3)))\n",
    "            \n",
    "        if (not changed) | (set(included)==set(upper)) | (set(included)==set(lower)):\n",
    "            if included:\n",
    "                formula = 'y~{}'.format('+'.join(included))\n",
    "            else:\n",
    "                formula = 'y~1'\n",
    "\n",
    "            model = smf.glm(formula, data,family=sm.families.Binomial()).fit()\n",
    "            print('\\n')\n",
    "            print(model.summary2())\n",
    "            break\n",
    "    return included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step : AIC = 47.857\n",
      "y~x2\n",
      "\t AIC\n",
      "+ x3 \t 36.829\n",
      "<none>\t 47.857\n",
      "+ x1 \t 48.56\n",
      "+ x4 \t 49.767\n",
      "- x2 \t 65.421\n",
      ">> Add x3 with AIC 36.829 \n",
      "\n",
      "Step : AIC = 36.829\n",
      "y~x2+x3\n",
      "\t AIC\n",
      "+ x1 \t 36.514\n",
      "<none>\t 36.829\n",
      "+ x4 \t 37.133\n",
      "- x2 \t 39.344\n",
      "- x3 \t 47.857\n",
      ">> Add x1 with AIC 36.514 \n",
      "\n",
      "Step : AIC = 36.514\n",
      "y~x2+x3+x1\n",
      "\t AIC\n",
      "- x2 \t 34.636\n",
      "<none>\t 36.514\n",
      "- x1 \t 36.829\n",
      "+ x4 \t 37.443\n",
      "- x3 \t 48.56\n",
      ">> Drop x2 with AIC 34.636 \n",
      "\n",
      "Step : AIC = 34.636\n",
      "y~x3+x1\n",
      "\t AIC\n",
      "<none>\t 34.636\n",
      "+ x4 \t 35.516\n",
      "+ x2 \t 36.514\n",
      "- x1 \t 39.344\n",
      "- x3 \t 47.65\n",
      "\n",
      "\n",
      "              Results: Generalized linear model\n",
      "==============================================================\n",
      "Model:              GLM              AIC:            34.6356  \n",
      "Link Function:      logit            BIC:            -135.9960\n",
      "Dependent Variable: y                Log-Likelihood: -14.318  \n",
      "Date:               2021-03-03 21:19 LL-Null:        -31.711  \n",
      "No. Observations:   46               Deviance:       28.636   \n",
      "Df Model:           2                Pearson chi2:   60.8     \n",
      "Df Residuals:       43               Scale:          1.0000   \n",
      "Method:             IRLS                                      \n",
      "---------------------------------------------------------------\n",
      "            Coef.   Std.Err.     z     P>|z|    [0.025   0.975]\n",
      "---------------------------------------------------------------\n",
      "Intercept  -5.9402    1.9855  -2.9917  0.0028  -9.8317  -2.0486\n",
      "x3          3.0191    1.0021   3.0128  0.0026   1.0551   4.9832\n",
      "x1          6.5564    2.9055   2.2566  0.0240   0.8618  12.2510\n",
      "==============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['x3', 'x1']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stepwise_logistic_aic_scope(bank,X,y, \n",
    "                            start=['x2'], upper=['x1','x2','x3','x4'], lower=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 분할 및 교차검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35.97804036473356, 27.443234484469368)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm0=smf.glm(formula = 'y ~ 1', \n",
    "           data=bank, family=sm.families.Binomial()).fit()\n",
    "(fm2.llf-fm0.llf)*2, -fm2.llf*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((46, 5), (32, 5), (14, 5))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "bank_train, bank_test = train_test_split(bank, test_size=0.3, random_state=10) #random_state 를 특정값으로 고정해야함 옵션이 없으면 시행마다 다른 숫자\n",
    "bank.shape, bank_train.shape, bank_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4236317835278336"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm2_tr=smf.glm(formula = 'y ~ x1 + x2 + x3 + x4', \n",
    "           data=bank_train, family=sm.families.Binomial()).fit()\n",
    "p=fm2_tr.predict(bank_test)\n",
    "yte=bank_test[\"y\"]\n",
    "-sum(yte*np.log(p)+(1-yte)*np.log(1-p))   # -loglikelihood on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9753865555360206"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm1_tr=smf.glm(formula = 'y ~ x1 + x3 ', \n",
    "           data=bank_train, family=sm.families.Binomial()).fit()\n",
    "p=fm1_tr.predict(bank_test)\n",
    "yte=bank_test[\"y\"]\n",
    "-sum(yte*np.log(p)+(1-yte)*np.log(1-p))   # -loglikelihood on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K - fold 를 이용한 검증\n",
    "- 훈련데이터로 두 모형 적합\n",
    "- 실험데이터에 대한 적합도 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.520810647011532, 7.206015359368315)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "scores1 = np.zeros(5)\n",
    "scores2 = np.zeros(5)\n",
    "cv = KFold(5, shuffle=True, random_state=0)\n",
    "\n",
    "for i, (idx_train, idx_test) in enumerate(cv.split(bank)):\n",
    "    bank_train = bank.iloc[idx_train]\n",
    "    bank_test = bank.iloc[idx_test]\n",
    "    \n",
    "    yte=bank_test[\"y\"]\n",
    "\n",
    "    fm1_tr=smf.glm(formula = 'y ~ x1 + x3 ', \n",
    "           data=bank_train, family=sm.families.Binomial()).fit()\n",
    "    fm2_tr=smf.glm(formula = 'y ~ x1 + x2 + x3 + x4', \n",
    "           data=bank_train, family=sm.families.Binomial()).fit()\n",
    "    \n",
    "    p=fm1_tr.predict(bank_test)\n",
    "    scores1[i] = -(yte*np.log(p)+(1-yte)*np.log(1-p)).sum()   \n",
    "\n",
    "    p=fm2_tr.predict(bank_test)\n",
    "    scores2[i] = -(yte*np.log(p)+(1-yte)*np.log(1-p)).sum()\n",
    "\n",
    "scores1.mean(), scores2.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn에서 로지스틱회귀분석\n",
    "##### Note: The intercept is regularized in sklearn but not in R. The option penalty='none' is not supported for the liblinear solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.31951669]\n",
      "[[ 7.13779753 -3.70328691  3.4148359  -2.96838772]]\n"
     ]
    }
   ],
   "source": [
    "X=bank.values[:,:4]\n",
    "y=bank.values[:,4]\n",
    "# 또는 \n",
    "#X = bank.loc[:,'x1':'x4']\n",
    "#y = bank['y']\n",
    "log_reg=LogisticRegression(penalty='none')    \n",
    "fit1=log_reg.fit(X,y)\n",
    "print(fit1.intercept_)\n",
    "print(fit1.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.31951257]\n",
      "[[ 7.13780424 -3.70332948  3.41483434 -2.96839048]]\n"
     ]
    }
   ],
   "source": [
    "X=bank.values[:,:4]\n",
    "y=bank.values[:,4]\n",
    "# 또는 \n",
    "#X = bank.loc[:,'x1':'x4']\n",
    "#y = bank['y']\n",
    "log_reg=LogisticRegression(solver='newton-cg', penalty='none')    \n",
    "fit1=log_reg.fit(X,y)\n",
    "print(fit1.intercept_)\n",
    "print(fit1.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.73999853]\n",
      "[[ 4.64735608  1.75824501  3.16070785 -2.98478736]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "X=bank.values[:,:4]\n",
    "y=bank.values[:,4]\n",
    "# 또는 \n",
    "#X = bank.loc[:,'x1':'x4']\n",
    "#y = bank['y']\n",
    "log_reg=LogisticRegression(solver='sag', penalty='none')    \n",
    "fit1=log_reg.fit(X,y)\n",
    "print(fit1.intercept_)\n",
    "print(fit1.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept   -5.319513\n",
       "x1           7.137804\n",
       "x2          -3.703330\n",
       "x3           3.414834\n",
       "x4          -2.968390\n",
       "dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(fm2)\n",
    "fm2.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예제: iris data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmp/opt/anaconda3/envs/yonsei/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X = iris['data'][:,2:]                    # 오른쪽 두 컬럼 \n",
    "y = (iris['target']==2).astype(np.int)    # T/F를 0/1로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-45.27188876]\n",
      "[[ 5.75446795 10.44661558]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression                     #싸이킷런: 머신러닝도구\n",
    "log_reg=LogisticRegression(solver='newton-cg', penalty=\"none\")\n",
    "fit1=log_reg.fit(X,y)\n",
    "print(fit1.intercept_)\n",
    "print(fit1.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-17.5481106]\n",
      "[[2.77762524 2.38552012]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression                     #싸이킷런: 머신러닝도구\n",
    "log_reg=LogisticRegression()\n",
    "fit2=log_reg.fit(X,y)\n",
    "print(fit2.intercept_)\n",
    "print(fit2.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data=pd.DataFrame(np.c_[X,y],columns=['x1','x2','y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>   150</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td>   147</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>     <th>  Df Model:          </th>  <td>     2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -10.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Mon, 29 Mar 2021</td> <th>  Deviance:          </th> <td>  20.564</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>12:33:58</td>     <th>  Pearson chi2:      </th>  <td>  20.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>10</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>  -45.2723</td> <td>   13.611</td> <td>   -3.326</td> <td> 0.001</td> <td>  -71.950</td> <td>  -18.594</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>        <td>    5.7545</td> <td>    2.306</td> <td>    2.496</td> <td> 0.013</td> <td>    1.235</td> <td>   10.274</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>        <td>   10.4467</td> <td>    3.756</td> <td>    2.782</td> <td> 0.005</td> <td>    3.086</td> <td>   17.808</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                  150\n",
       "Model:                            GLM   Df Residuals:                      147\n",
       "Model Family:                Binomial   Df Model:                            2\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -10.282\n",
       "Date:                Mon, 29 Mar 2021   Deviance:                       20.564\n",
       "Time:                        12:33:58   Pearson chi2:                     20.1\n",
       "No. Iterations:                    10                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept    -45.2723     13.611     -3.326      0.001     -71.950     -18.594\n",
       "x1             5.7545      2.306      2.496      0.013       1.235      10.274\n",
       "x2            10.4467      3.756      2.782      0.005       3.086      17.808\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3 = smf.glm(formula = 'y~x1+x2',data=data,family=sm.families.Binomial())\n",
    "fit3 = m3.fit()\n",
    "fit3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다항 로지스틱 회귀모형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.068555\n",
      "         Iterations: 35\n",
      "         Function evaluations: 36\n",
      "         Gradient evaluations: 36\n",
      "         Hessian evaluations: 35\n",
      "                          MNLogit Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  150\n",
      "Model:                        MNLogit   Df Residuals:                      144\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Mon, 29 Mar 2021   Pseudo R-squ.:                  0.9376\n",
      "Time:                        12:34:00   Log-Likelihood:                -10.283\n",
      "converged:                      False   LL-Null:                       -164.79\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.229e-65\n",
      "==============================================================================\n",
      "       y=1       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    -27.2178     90.934     -0.299      0.765    -205.445     151.009\n",
      "x1             7.4524     81.169      0.092      0.927    -151.636     166.541\n",
      "x2            11.8870    195.782      0.061      0.952    -371.839     395.613\n",
      "------------------------------------------------------------------------------\n",
      "       y=2       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    -72.4992     91.948     -0.788      0.430    -252.713     107.715\n",
      "x1            13.2083     81.202      0.163      0.871    -145.945     172.361\n",
      "x2            22.3352    195.818      0.114      0.909    -361.461     406.132\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmp/opt/anaconda3/envs/yonsei/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "X = iris['data'][:,(2,3)]                     \n",
    "y = iris['target']\n",
    "data=pd.DataFrame(np.c_[X,y],columns=['x1','x2','y'])\n",
    "fit_mn1 = smf.mnlogit(formula='y~x1+x2',data=data).fit(method='ncg')\n",
    "print(fit_mn1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fopt': 0.06855457926002029,\n",
       " 'fcalls': 36,\n",
       " 'gcalls': 36,\n",
       " 'hcalls': 35,\n",
       " 'warnflag': 1,\n",
       " 'converged': False}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_mn1.mle_retvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.111439\n",
      "         Iterations: 35\n",
      "         Function evaluations: 36\n",
      "         Gradient evaluations: 36\n",
      "         Hessian evaluations: 35\n",
      "                          MNLogit Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  150\n",
      "Model:                        MNLogit   Df Residuals:                      146\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Mon, 29 Mar 2021   Pseudo R-squ.:                  0.8986\n",
      "Time:                        12:34:02   Log-Likelihood:                -16.716\n",
      "converged:                      False   LL-Null:                       -164.79\n",
      "Covariance Type:            nonrobust   LLR p-value:                 4.914e-65\n",
      "==============================================================================\n",
      "       y=1       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    -26.5489     53.603     -0.495      0.620    -131.608      78.510\n",
      "x2            34.5122     66.606      0.518      0.604     -96.032     165.057\n",
      "------------------------------------------------------------------------------\n",
      "       y=2       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    -47.6531     53.799     -0.886      0.376    -153.097      57.791\n",
      "x2            47.4464     66.666      0.712      0.477     -83.217     178.110\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmp/opt/anaconda3/envs/yonsei/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "X = iris['data'][:,(2,3)]                     \n",
    "y = iris['target']\n",
    "data=pd.DataFrame(np.c_[X,y],columns=['x1','x2','y'])\n",
    "fit_mn1 = smf.mnlogit(formula='y~x2',data=data).fit(method='ncg')\n",
    "print(fit_mn1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.068555\n",
      "         Iterations: 35\n",
      "         Function evaluations: 36\n",
      "         Gradient evaluations: 36\n",
      "         Hessian evaluations: 35\n",
      "                          MNLogit Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  150\n",
      "Model:                        MNLogit   Df Residuals:                      144\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Mon, 29 Mar 2021   Pseudo R-squ.:                  0.9376\n",
      "Time:                        12:34:03   Log-Likelihood:                -10.283\n",
      "converged:                      False   LL-Null:                       -164.79\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.229e-65\n",
      "==============================================================================\n",
      "       y=1       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -27.2178     90.934     -0.299      0.765    -205.445     151.009\n",
      "x1             7.4524     81.169      0.092      0.927    -151.636     166.541\n",
      "x2            11.8870    195.782      0.061      0.952    -371.839     395.613\n",
      "------------------------------------------------------------------------------\n",
      "       y=2       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -72.4992     91.948     -0.788      0.430    -252.713     107.715\n",
      "x1            13.2083     81.202      0.163      0.871    -145.945     172.361\n",
      "x2            22.3352    195.818      0.114      0.909    -361.461     406.132\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmp/opt/anaconda3/envs/yonsei/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X = iris['data'][:,(2,3)]                     \n",
    "X = sm.add_constant(X)\n",
    "y = iris['target']\n",
    "\n",
    "fit_mn1a = sm.MNLogit(y, X).fit(method='ncg')\n",
    "print(fit_mn1a.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 36.9463   4.163  -41.1093]\n",
      "[[ -7.9636 -12.7065]\n",
      " [  1.1045   1.1299]\n",
      " [  6.8591  11.5766]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "X = iris['data'][:,(2,3)]                            # 오른쪽 두 컬럼 \n",
    "y = iris['target']\n",
    "fit_mn2=LogisticRegression(multi_class='multinomial',solver ='newton-cg',penalty='none').fit(X,y)\n",
    "print(fit_mn2.intercept_.round(4))\n",
    "print(fit_mn2.coef_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.    , 0.0122, 0.9878]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_mn1a.predict([[1,5,2]]).round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03556, 0.96444, 0.     ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_mn1a.predict([[1,2.5,1]]).round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.    , 0.0122, 0.9878]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_mn2.predict_proba([[5,2]]).round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02358, 0.97642, 0.     ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_mn2.predict_proba([[2.5,1]]).round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50  0  0]\n",
      " [ 0 48  2]\n",
      " [ 0  4 46]]\n"
     ]
    }
   ],
   "source": [
    "pred1=fit_mn1.predict().argmax(1)\n",
    "print(confusion_matrix(y, pred1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
